{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "img_channels = 1\n",
    "num_pixels = img_cols*img_rows\n",
    "num_classes = 10\n",
    "num_trainImages = 42000\n",
    "num_testImages = 28000\n",
    "\n",
    "yTrain = np.ones((num_trainImages))\n",
    "xTrain = np.ones((num_trainImages,img_channels,img_cols,img_rows))\n",
    "counter = 0\n",
    "skip = True\n",
    "\n",
    "# train.csv should be in the same folder as this file\n",
    "trainFile = open('datasets/train.csv')\n",
    "csv_file = csv.reader(trainFile)\n",
    "for row in csv_file:\n",
    "    if (skip == True):\n",
    "        skip = False\n",
    "        continue\n",
    "    yTrain[counter] = row[0]\n",
    "    temp = np.ones((1,num_pixels))\n",
    "    for num in range(1,num_pixels):\n",
    "        temp[0,num - 1] = row[num]\n",
    "    temp = (temp - np.mean(temp))/(np.max(temp) - np.min(temp))\n",
    "    temp = np.reshape(temp, (img_rows,img_cols))\n",
    "    xTrain[counter,0,:,:] = temp\n",
    "    counter += 1\n",
    "\n",
    "yTest = np.ones((num_testImages))\n",
    "xTest = np.ones((num_testImages,img_channels,img_cols,img_rows))\n",
    "skip2 = True\n",
    "counter2 = 0\n",
    "\n",
    "testFile = open('datasets/test.csv')\n",
    "csv_file2 = csv.reader(testFile)\n",
    "for row in csv_file2:\n",
    "    if (skip2 == True):\n",
    "        skip2 = False\n",
    "        continue\n",
    "    yTest[counter2] = row[0]\n",
    "    temp = np.ones((1,num_pixels))\n",
    "    for num in range(1,num_pixels):\n",
    "        temp[0,num - 1] = row[num]\n",
    "    temp = (temp - np.mean(temp))/(np.max(temp) - np.min(temp))\n",
    "    temp = np.reshape(temp, (img_rows,img_cols))\n",
    "    xTest[counter2,0,:,:] = temp\n",
    "    counter2 += 1\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "yTrain = np_utils.to_categorical(yTrain, num_classes)\n",
    "yTest = np_utils.to_categorical(yTest, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(img_channels,img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64,  kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(96,  kernel_size = (3,3), padding = 'Same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATASET\n",
    "xTrain.shape\n",
    "vTrain = xTrain[33600:42000,:,:,:]\n",
    "vTest = yTrain[33600:42000,:]\n",
    "xTrain = xTrain[:33600,:,:,:]\n",
    "yTrain = yTrain[:33600,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TRAINING with TENSORBOARD\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "\n",
    "#Instantiate it like so:\n",
    "tensorboard = TrainValTensorBoard(log_dir='/home/tuzunneslihan/MNIST/keras')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "history = model.fit(xTrain, yTrain, batch_size=32, nb_epoch=8,validation_data=(vTrain, vTest),shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0316 20:40:42.376782 139816856507776 training.py:686] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 10s 288us/sample - loss: 2.3004 - accuracy: 0.1221 - val_loss: 2.2982 - val_accuracy: 0.1763\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 8s 229us/sample - loss: 2.2966 - accuracy: 0.1576 - val_loss: 2.2939 - val_accuracy: 0.2680\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 7s 223us/sample - loss: 2.2922 - accuracy: 0.1976 - val_loss: 2.2887 - val_accuracy: 0.3352\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 7s 222us/sample - loss: 2.2867 - accuracy: 0.2389 - val_loss: 2.2819 - val_accuracy: 0.3780\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 7s 223us/sample - loss: 2.2791 - accuracy: 0.2745 - val_loss: 2.2726 - val_accuracy: 0.3996\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 7s 222us/sample - loss: 2.2686 - accuracy: 0.3065 - val_loss: 2.2594 - val_accuracy: 0.4279\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 7s 223us/sample - loss: 2.2539 - accuracy: 0.3308 - val_loss: 2.2407 - val_accuracy: 0.4583\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 7s 222us/sample - loss: 2.2326 - accuracy: 0.3571 - val_loss: 2.2138 - val_accuracy: 0.5014\n",
      "28000/28000 [==============================] - 2s 55us/sample\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.fit(xTrain, yTrain, batch_size=32, nb_epoch=8,validation_data=(vTrain, vTest),shuffle=True)\n",
    "\n",
    "results = np.zeros((num_testImages,2))\n",
    "for num in range(1,num_testImages + 1):\t\n",
    "    results[num - 1,0] = num\n",
    "\n",
    "# TESTING\n",
    "temp = model.predict_classes(xTest, batch_size=32, verbose=1)\n",
    "for num in range(0,num_testImages):\t\n",
    "    results[num,1] = temp[num]\n",
    "# Results saved in this text file\n",
    "np.savetxt('submission.csv', results, delimiter=',', fmt = '%i')  \n",
    "results = pd.np.array(results)\n",
    "firstRow = [[0 for x in range(2)] for x in range(1)]\n",
    "firstRow[0][0] = 'ImageId'\n",
    "firstRow[0][1] = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
